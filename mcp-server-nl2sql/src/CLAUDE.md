# SQL Validator Design Documentation

## Overview

This validator implements robust SQL validation for a Natural Language to SQL (NL2SQL) system. It validates SQL queries generated by an AI model (Hrida via Ollama) before execution against a PostgreSQL database.

**Key Goals:**
- Safety: Prevent SQL injection and dangerous operations
- Reliability: Handle edge cases properly (strings, comments, dollar-quoting)
- Repairability: Return structured feedback for AI model to retry
- Scalability: Design extends to enterprise schemas without rewrite

## Architecture

### Flow Diagram

```
┌─────────────────────┐
│ 1. Generate SQL     │
│    (Python/Hrida)   │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ 2. Tokenize SQL     │
│    (State Machine)  │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ 3. Validate         │
│    (Multiple Rules) │
└──────────┬──────────┘
           │
      ┌────┴────┐
      │ Valid?  │
      └────┬────┘
     No    │    Yes
      ┌────┴────┐
      │         │
      ▼         ▼
┌─────────┐  ┌────────────┐
│Auto-fix?│  │4. EXPLAIN  │
│  or     │  │   (Postgres)│
│Rewrite? │  └──────┬─────┘
└────┬────┘         │
     │         ┌────┴────┐
     │         │Success? │
     │         └────┬────┘
     │        No   │   Yes
     │         ┌───┴───┐
     │         │       │
     ▼         ▼       ▼
┌─────────┐ ┌─────────┐ ┌────────┐
│Repair   │ │Repair   │ │Execute │
│Loop     │ │Loop     │ │& Return│
│(max 3)  │ │(max 3)  │ └────────┘
└─────────┘ └─────────┘
```

### Components

**sql_validator.ts** - Main validator with state machine tokenizer
**config.ts** - TypeScript types and configuration
**python_client.ts** - HTTP client to Python sidecar
**nl_query_tool.ts** - Orchestrates validation → repair loop → execution

---

## Key Design Decisions & Gotchas

### 1. Semicolons Are Optional (NOT Required)

**Decision**: `MISSING_SEMICOLON` is `info` severity, `auto_fix` action.

**Rationale**:
- PostgreSQL drivers (pg, psycopg) do NOT require semicolons for single statements
- Requiring them creates weird edge cases in repair loops
- Model may struggle to consistently add/remove semicolons

**Implementation**:
```typescript
// Optional: Add trailing semicolon if missing (info only, auto-fix)
if (semicolonPositions.length === 0) {
    currentSQL = currentSQL + ";"
    autoFixed = true
    issues.push({
        code: "MISSING_SEMICOLON",
        severity: "info",  // NOT error!
        action: "auto_fix",
        message: "Added trailing semicolon for consistency",
    })
}
```

**Prompt Guidance**: Do NOT instruct Hrida "must end with semicolon" unless output consistency testing shows it helps.

---

### 2. Multiple Statement Detection Uses State Machine (NOT `split(';')`)

**Problem**: Naively splitting by `;` breaks on:
- Semicolons inside strings: `SELECT 'hello; world'`
- Semicolons inside comments: `SELECT 1 -- ; comment`
- Semicolons inside dollar-quoted strings: `SELECT $$a;b$$`

**Solution**: Tokenize SQL with state machine that tracks:
- Single quotes `'...'` with `''` escaping
- Double quotes `"..."` with `""` escaping
- Dollar quotes `$tag$...$tag$` and `$$...$$`
- Line comments `-- ...`
- Block comments `/* ... */`

**Implementation**:
```typescript
function tokenizeSQL(sql: string): Token[] {
    // State machine tracks position and context
    // Returns tokens typed as: NORMAL, SINGLE_QUOTE, DOUBLE_QUOTE,
    //                         DOLLAR_QUOTE, LINE_COMMENT, BLOCK_COMMENT
}

function checkMultipleStatements(tokens: Token[]) {
    // Only check semicolons in NORMAL tokens (outside strings/comments)
    const normalTokens = getNormalTokens(tokens)
    // ... count semicolons, check if any are statement terminators
}
```

**What counts as "multiple statements":**
- ✅ Allowed: `SELECT * FROM companies;` (one statement with trailing semicolon)
- ✅ Allowed: `SELECT * FROM companies` (one statement, no semicolon)
- ✅ Allowed: `SELECT 'hello; world'` (semicolon in string, one statement)
- ❌ Rejected: `SELECT * FROM companies; SELECT * FROM revenue;` (two statements)
- ❌ Rejected: `SELECT * FROM companies; DROP TABLE companies;` (SQL injection attempt)

---

### 3. Dangerous Keyword Checks Must Ignore Strings/Comments

**Problem**: Naive `sql.toUpperCase().includes('DROP')` triggers on:
- Column names: `SELECT dropoff_location FROM trips`
- String literals: `SELECT 'please do not drop' AS warning`
- Comments: `SELECT 1 -- DROP this comment later`

**Solution**: Only check keywords in NORMAL tokens (outside strings/comments).

**Implementation**:
```typescript
function checkDangerousKeywords(tokens: Token[]) {
    const normalTokens = getNormalTokens(tokens)

    for (const token of normalTokens) {
        for (const keyword of DANGEROUS_KEYWORDS) {
            // Match whole word only
            const regex = new RegExp(`\\b${keyword}\\b`, "gi")
            if (regex.test(token.value)) {
                found.push(keyword)
            }
        }
    }
}
```

**Blocked keywords (checked in code only)**:
- DDL: DROP, CREATE, ALTER, TRUNCATE, RENAME
- DML (writes): INSERT, UPDATE, DELETE
- DCL: GRANT, REVOKE
- TCL: BEGIN, COMMIT, ROLLBACK, SAVEPOINT
- Other: COPY, EXECUTE, PREPARE

---

### 4. Dangerous Functions Are Blocked (Admin/File I/O)

**Problem**: Even with "SELECT only", dangerous functions can be exploited:
- `SELECT pg_read_file('/etc/passwd')`
- `SELECT pg_ls_dir('/var/log')`
- `SELECT pg_sleep(9999)` (DoS)

**Solution**: Block dangerous functions by detecting function call patterns `func_name(`

**Blocked functions**:
- File I/O: `pg_read_file`, `pg_read_binary_file`, `pg_ls_dir`, `lo_export`, `lo_import`
- System: `pg_sleep`, `pg_terminate_backend`, `pg_cancel_backend`
- External: `dblink`, `dblink_connect`, `dblink_exec`, `postgres_fdw`
- Admin: `pg_reload_conf`, `pg_rotate_logfile`, `pg_stat_reset`

**Implementation**:
```typescript
function checkDangerousFunctions(tokens: Token[]) {
    const normalTokens = getNormalTokens(tokens)

    for (const func of DANGEROUS_FUNCTIONS) {
        // Match function call: func_name(
        const regex = new RegExp(`\\b${func}\\s*\\(`, "gi")
        // Only check in NORMAL tokens (outside strings/comments)
    }
}
```

---

### 5. Table Allowlist: Best-Effort Extraction (MVP)

**Current approach** (regex-based, not full parser):
- Extract from patterns: `FROM <table>`, `JOIN <table>`
- Handle schema-qualified: `schema.table`
- Handle quoted identifiers: `"table_name"`
- Normalize to lowercase
- Check against allowlist

**Limitations (acceptable for MVP)**:
- Doesn't parse subqueries perfectly
- Doesn't handle all CTE (WITH clause) cases
- Doesn't detect tables in functions (e.g., `json_to_recordset('table_name')`)

**Implementation**:
```typescript
function extractTableNames(tokens: Token[]): string[] {
    const normalTokens = getNormalTokens(tokens)
    const normalSQL = normalTokens.map(t => t.value).join("")

    // Patterns for FROM/JOIN
    const patterns = [
        /\bFROM\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)?)/gi,
        /\bJOIN\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)?)/gi,
        /\bFROM\s+"([^"]+)"/gi,
        /\bJOIN\s+"([^"]+)"/gi,
    ]

    // Extract, normalize, deduplicate
    return Array.from(new Set(tables))
}
```

**Enforcement from multiple angles**:
1. **Model constraint** (in prompt): "use only these tables: companies, company_revenue_annual"
2. **Validator enforcement** (hard gate): Reject if SQL references other tables
3. **DB role enforcement** (ultimate backstop): Read-only role + schema scoping

**Future enhancement**: Use a real SQL parser (e.g., `pgsql-parser`) for 100% accurate table extraction.

---

### 6. LIMIT Enforcement: Auto-Fix for Safety

**Rule**: Queries SHOULD have `LIMIT`, `FETCH FIRST`, or `FETCH NEXT`.

**Action**: Auto-fix by adding `LIMIT 1000` (configurable via `context.maxLimit`)

**Why auto-fix, not reject?**
- Model may forget LIMIT in complex queries
- Better UX to auto-add than force retry
- Safety: Prevents accidental massive result sets

**Implementation**:
```typescript
if (requireLimit && !hasLimitClause(currentSQL)) {
    const maxLimit = context.maxLimit || 1000
    if (currentSQL.endsWith(";")) {
        currentSQL = currentSQL.slice(0, -1) + ` LIMIT ${maxLimit};`
    } else {
        currentSQL = currentSQL + ` LIMIT ${maxLimit}`
    }
    autoFixed = true
    issues.push({
        code: "MISSING_LIMIT",
        severity: "warning",
        action: "auto_fix",
        message: `Added LIMIT ${maxLimit} for safety`,
    })
}
```

**Detection includes**:
- `LIMIT n`
- `FETCH FIRST n ROWS ONLY`
- `FETCH NEXT n ROWS ONLY`

---

### 7. EXPLAIN-First Safety with Timeout

**Strategy**: Before executing, run `EXPLAIN (FORMAT JSON)` to catch errors safely.

**Benefits**:
- Detects syntax errors without execution
- Detects undefined tables/columns
- Detects type mismatches
- Can analyze plan for cartesian products

**Safeguards** (important!):
1. **Never use ANALYZE**: `EXPLAIN (FORMAT JSON, ANALYZE FALSE)` (default is no ANALYZE anyway)
2. **Set statement timeout**: `SET LOCAL statement_timeout = '2s'` in transaction
3. **Cost-based skip**: Optionally skip EXPLAIN for very simple queries (e.g., `SELECT COUNT(*)`)

**Implementation** (in nl_query_tool.ts):
```typescript
// Run EXPLAIN first (safe - no execution)
try {
    await client.query(`BEGIN`);
    await client.query(`SET LOCAL statement_timeout = '2s'`);

    const explainResult = await client.query(
        `EXPLAIN (FORMAT JSON) ${sql}`
    );

    // Optional: Analyze plan for warnings
    const warnings = analyzeExplainPlan(explainResult.rows[0]);

    await client.query(`COMMIT`);

    // EXPLAIN succeeded - safe to execute
    return await executeQuery(sql, context);

} catch (pgError) {
    await client.query(`ROLLBACK`);

    const errorContext = parsePostgresError(pgError);

    if (isFailFastError(errorContext.sqlstate)) {
        throw new DatabaseError(errorContext);
    }

    // Retry with repair if repairable
    // ...
}
```

**When to skip EXPLAIN**:
- Very simple queries: `SELECT COUNT(*) FROM companies;`
- After N successful EXPLAINs for same question pattern

---

### 8. Issue Compression for Repair Prompts

**Problem**: Passing raw validator issues to AI model bloats prompt:
```
❌ [UNKNOWN_TABLE] Unknown tables: companie
⚠️ [MISSING_LIMIT] Added LIMIT 1000 for safety
❌ [DANGEROUS_KEYWORD] Dangerous keywords detected: DROP
```

**Solution**: Compress to short, actionable instructions:
```
- Use only these tables: companies, company_revenue_annual
- Remove write operations (INSERT/UPDATE/DELETE/DROP/etc)
```

**Implementation**:
```typescript
export function compressIssuesForRepair(issues: ValidationIssue[]): string[] {
    const instructions: string[] = []
    const seen = new Set<string>()

    for (const issue of issues) {
        let instruction = ""

        switch (issue.code) {
            case "UNKNOWN_TABLE":
                instruction = issue.suggestion || "Use only allowed tables"
                break
            case "DANGEROUS_KEYWORD":
                instruction = "Remove write operations (INSERT/UPDATE/DELETE/DROP/etc)"
                break
            // ... other cases
        }

        // Deduplicate
        if (!seen.has(instruction)) {
            seen.add(instruction)
            instructions.push(instruction)
        }
    }

    return instructions
}
```

---

## Validation Rules Reference

### Issue Taxonomy

| Code | Severity | Action | Repairable | Auto-fixable | Description |
|------|----------|--------|------------|--------------|-------------|
| `NO_SELECT` | error | fail_fast | ❌ | ❌ | Query must start with SELECT |
| `MULTIPLE_STATEMENTS` | error | fail_fast | ❌ | ❌ | Multiple statements detected |
| `DANGEROUS_KEYWORD` | error | fail_fast | ❌ | ❌ | DROP/UPDATE/DELETE/etc detected |
| `DANGEROUS_FUNCTION` | error | fail_fast | ❌ | ❌ | pg_read_file/COPY/etc detected |
| `UNKNOWN_TABLE` | error | rewrite | ✅ | ❌ | Table not in allowlist |
| `MISSING_SEMICOLON` | info | auto_fix | ✅ | ✅ | No semicolon (adds one) |
| `MISSING_LIMIT` | warning | auto_fix | ✅ | ✅ | No LIMIT (adds default) |
| `EXCESSIVE_JOINS` | warning | review | ✅ | ❌ | More than 5 JOINs |

### Actions Explained

- **fail_fast**: Security violation or irrecoverable error. Reject immediately, do not retry.
- **auto_fix**: Can be fixed automatically by validator. No model retry needed.
- **rewrite**: Model should retry with error feedback.
- **review**: Warning only, query is executable but may need attention.

---

## PostgreSQL Error Handling

### SQLSTATE Classification

**Fail-Fast SQLSTATEs** (never retry):

| Class | Range | Meaning | Example |
|-------|-------|---------|---------|
| Connection | `08xxx` | Connection errors | Cannot reach database |
| Permissions | `42501` | Insufficient privilege | User lacks SELECT permission |
| Resource | `53xxx` | Insufficient resources | Out of memory |
| System | `58xxx` | System error | Disk full |
| Config | `F0xxx` | Config file error | Invalid postgresql.conf |
| Internal | `XXxxx` | Internal error | Database bug |

**Repairable SQLSTATEs** (retry with model):

| Code | Meaning | Repair Strategy |
|------|---------|-----------------|
| `42601` | Syntax error | Fix syntax based on error message |
| `42P01` | Undefined table | Use correct table name from allowlist |
| `42703` | Undefined column | Use correct column name from schema |
| `42P09` | Ambiguous column | Add table alias to resolve |
| `42P10` | Invalid column reference | Qualify column with table name |
| `42804` | Datatype mismatch | Fix comparison types (e.g., text vs integer) |
| `42883` | Undefined function | Fix function name or arguments |
| `57014` | Query canceled / timeout | Simplify query or add filters |

**Implementation**:
```typescript
function isFailFastError(sqlstate: string): boolean {
    const failFastPrefixes = ['08', '53', '58', 'F0', 'XX']
    if (sqlstate === '42501') return true  // Permission denied
    return failFastPrefixes.some(prefix => sqlstate.startsWith(prefix))
}

function isRepairableError(sqlstate: string): boolean {
    const repairableCodes = [
        '42601', '42P01', '42703', '42P09', '42P10',
        '42804', '42883', '57014'
    ]
    return repairableCodes.includes(sqlstate)
}
```

---

## Repair Loop Design

### Bounded Loop (Max 2-3 Attempts)

```typescript
async function validateWithRepair(question: string, context: QueryContext) {
    const maxAttempts = 3
    let attempt = 0
    let sql = await pythonClient.generateSQL({ question, ...context })

    while (attempt < maxAttempts) {
        attempt++

        // Step 1: Structural validation
        const validation = validateSQL(sql, context)

        if (validation.issues.some(i => i.action === 'fail_fast')) {
            throw new SafetyViolationError(validation.issues)
        }

        if (validation.autoFixed) {
            sql = validation.sql
        }

        if (!validation.valid && validation.issues.some(i => i.action === 'rewrite')) {
            // Repair loop
            sql = await pythonClient.repairSQL({
                question,
                previousSQL: sql,
                validatorIssues: validation.issues,
                attempt,
                maxAttempts
            })
            continue
        }

        // Step 2: EXPLAIN check (with timeout)
        try {
            await client.query(`SET LOCAL statement_timeout = '2s'`)
            await client.query(`EXPLAIN (FORMAT JSON) ${sql}`)

            // Success - execute
            return await executeQuery(sql, context)

        } catch (pgError) {
            const errorContext = parsePostgresError(pgError)

            if (isFailFastError(errorContext.sqlstate)) {
                throw new DatabaseError(errorContext)
            }

            if (attempt >= maxAttempts) {
                return createSafeFailure(errorContext, attempt)
            }

            // Retry with Postgres error context
            sql = await pythonClient.repairSQL({
                question,
                previousSQL: sql,
                validatorIssues: validation.issues,
                postgresError: errorContext,
                attempt,
                maxAttempts
            })
        }
    }

    return createSafeFailure({ message: 'Max attempts exceeded' }, maxAttempts)
}
```

---

## Python Prompt Composition

### Base + Delta Pattern (Never Mutate Base)

**Principle**: Maintain a versioned base prompt, append ephemeral "delta blocks" per attempt.

**Structure**:
```python
BASE_PROMPT_VERSION = "v1.2.0"

HRIDA_BASE_PROMPT = """
Generate PostgreSQL SELECT query for the {database_id} database.

## Database Schema
{schema}

## PostgreSQL Rules
[... static rules ...]

## Question
{question}

## SQL Query
"""

# Delta blocks (ephemeral, per-attempt)
REPAIR_DELTA_VALIDATOR = """
## Validation Issues from Previous Attempt

{validator_issues_formatted}

**Instructions:**
- Fix all validation errors listed above
- Use only these tables: {allowed_tables}
"""

REPAIR_DELTA_POSTGRES = """
## PostgreSQL Error from Previous Attempt

Error Code: {sqlstate}
Message: {message}
{hint_section}

Previous SQL:
{previous_sql}

**Instructions:**
- Analyze the Postgres error carefully
- {sqlstate_hint}
"""
```

**Composition Logic**:
```python
def compose_prompt(request, is_repair=False):
    # Start with base
    base = HRIDA_BASE_PROMPT.format(
        database_id=request.database_id,
        schema=format_schema(request.selected_tables),
        question=request.question
    )

    if not is_repair:
        return base

    # Append delta blocks (ephemeral)
    delta_blocks = []

    if request.validator_issues:
        delta_blocks.append(
            REPAIR_DELTA_VALIDATOR.format(
                validator_issues_formatted=format_issues(request.validator_issues),
                allowed_tables=", ".join(request.constraints.allowed_tables)
            )
        )

    if request.postgres_error:
        sqlstate_hint = SQLSTATE_HINTS.get(
            request.postgres_error.sqlstate,
            "Review error message carefully"
        )
        delta_blocks.append(
            REPAIR_DELTA_POSTGRES.format(
                sqlstate=request.postgres_error.sqlstate,
                message=request.postgres_error.message,
                hint_section=format_hint(request.postgres_error.hint),
                previous_sql=request.previous_sql,
                sqlstate_hint=sqlstate_hint
            )
        )

    # Compose: base + deltas (never mutate base)
    full_prompt = base + "\n\n" + "\n\n".join(delta_blocks)

    # Log composition metadata
    logger.debug("Prompt composed", {
        "base_version": BASE_PROMPT_VERSION,
        "is_repair": is_repair,
        "attempt": request.attempt,
        "delta_blocks": len(delta_blocks),
        "prompt_length": len(full_prompt)
    })

    return full_prompt
```

---

## Logging Requirements

Log on every attempt:
```python
logger.info("SQL generation attempt", {
    "query_id": query_id,
    "attempt": attempt,
    "max_attempts": max_attempts,
    "base_prompt_version": BASE_PROMPT_VERSION,
    "is_repair": is_repair,
    "validator_issues": [i.code for i in validator_issues],
    "sqlstate": postgres_error.sqlstate if postgres_error else None,
    "prompt_length": len(full_prompt),
    "sql_length": len(sql_generated)
})
```

Log on repair success:
```python
logger.info("SQL repaired successfully", {
    "query_id": query_id,
    "attempt": attempt,
    "repair_strategy": repair_strategy,
    "changes_made": changes_made,
    "confidence_before": previous_confidence,
    "confidence_after": new_confidence
})
```

---

## Testing Strategy

### Unit Tests

Test tokenizer edge cases:
```typescript
// Semicolons in strings
expect(tokenizeSQL("SELECT 'a;b'")[0].type).toBe(TokenType.SINGLE_QUOTE)

// Escaped quotes
expect(tokenizeSQL("SELECT 'it''s'")[0].value).toBe("'it''s'")

// Dollar quoting
expect(tokenizeSQL("SELECT $$a$b$$")[0].type).toBe(TokenType.DOLLAR_QUOTE)

// Comments
expect(tokenizeSQL("SELECT 1 -- ;")[1].type).toBe(TokenType.LINE_COMMENT)
```

Test validator rules:
```typescript
// Multiple statements rejected
const result = validateSQL("SELECT 1; DROP TABLE users;", context)
expect(result.valid).toBe(false)
expect(result.issues[0].code).toBe("MULTIPLE_STATEMENTS")

// String with semicolon allowed
const result2 = validateSQL("SELECT 'hello; world'", context)
expect(result2.valid).toBe(true)

// Auto-fix LIMIT
const result3 = validateSQL("SELECT * FROM companies", context)
expect(result3.autoFixed).toBe(true)
expect(result3.sql).toContain("LIMIT")
```

### Integration Tests

Test repair loop:
```typescript
// Test UNKNOWN_TABLE repair
const question = "How many customers are there?"
const result = await executeNLQuery({ question }, context)

// Should auto-correct "customers" → "companies"
expect(result.sql_generated).toContain("FROM companies")
expect(result.trace.attempts).toBeGreaterThan(1)
```

Test Postgres error handling:
```typescript
// Test undefined column repair
const question = "Show me company emails"
const result = await executeNLQuery({ question }, context)

// Should recognize "email" column doesn't exist
expect(result.error).toBeDefined()
expect(result.error.sqlstate).toBe("42703")
```

---

## Future Enhancements

### Phase 2: Real SQL Parser

Replace regex-based table extraction with `pgsql-parser`:
```typescript
import { parse } from 'pgsql-parser'

function extractTableNames(sql: string): string[] {
    const ast = parse(sql)
    // Traverse AST to find all table references
    // 100% accurate, handles all edge cases
}
```

### Phase 3: Semantic Analysis

Add EXPLAIN plan analysis:
```typescript
function analyzeExplainPlan(plan: any): ValidationIssue[] {
    const issues = []

    // Detect cartesian products
    if (hasNestedLoop(plan) && !hasJoinCondition(plan)) {
        issues.push({
            code: "CARTESIAN_PRODUCT",
            severity: "warning",
            action: "rewrite",
            message: "Query may produce cartesian product",
            suggestion: "Add JOIN condition or WHERE clause"
        })
    }

    // Detect sequential scans on large tables
    if (hasSeqScan(plan) && estimatedRows(plan) > 100000) {
        issues.push({
            code: "MISSING_INDEX",
            severity: "info",
            action: "review",
            message: "Query uses sequential scan on large table",
            suggestion: "Consider adding index or filters"
        })
    }

    return issues
}
```

### Phase 4: Query Complexity Scoring

```typescript
interface ComplexityScore {
    joins: number          // Number of joins
    subqueries: number     // Nested selects
    aggregates: number     // COUNT/SUM/AVG/etc
    windowFunctions: number
    totalScore: number     // Weighted sum
}

function scoreComplexity(sql: string): ComplexityScore {
    // Assign complexity score
    // Use to adjust max_attempts, timeout, confidence threshold
}
```

---

## References

- PostgreSQL Error Codes: https://www.postgresql.org/docs/current/errcodes-appendix.html
- PostgreSQL String Constants: https://www.postgresql.org/docs/current/sql-syntax-lexical.html#SQL-SYNTAX-DOLLAR-QUOTING
- SQL Injection Prevention: https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html

---

## Integration Testing Steps

### Phase 1: Standalone Component Testing

**Python Sidecar Testing** (Port 8001):
```bash
# 1. Start Python sidecar
cd ~/nl2sql-project/python-sidecar
source venv/bin/activate
OLLAMA_MODEL="HridaAI/hrida-t2sql:latest" python app.py

# 2. Test health check
curl http://localhost:8001/health

# 3. Test SQL generation
curl -X POST http://localhost:8001/generate_sql \
  -H "Content-Type: application/json" \
  -d '{"question": "How many companies?", "database_id": "mcptest"}'

# 4. Test repair loop (after implementation)
curl -X POST http://localhost:8001/repair_sql \
  -H "Content-Type: application/json" \
  -d '{
    "question": "How many companies?",
    "database_id": "mcptest",
    "previous_sql": "SELECT COUNT(*) FROM companie;",
    "validator_issues": [{"code": "UNKNOWN_TABLE", "message": "Unknown table: companie"}],
    "attempt": 1,
    "max_attempts": 3
  }'
```

**TypeScript MCP Server Testing** (Standalone):
```bash
# 1. Build server
cd ~/nl2sql-project/mcp-server-nl2sql
npm run build

# 2. Test with MCP inspector or Smithery CLI
smithery inspect .smithery/index.cjs

# 3. Test nl_query tool directly
# (Requires MCP client - LibreChat or test harness)
```

**Database Connectivity Testing**:
```bash
# Verify MCPtest database access
PGPASSWORD=treyco psql -h 172.28.91.130 -U mcptest -d mcptest \
  -c "SELECT COUNT(*) FROM companies;"

# Test with generated SQL
PGPASSWORD=treyco psql -h 172.28.91.130 -U mcptest -d mcptest \
  -c "SELECT c.name, AVG(r.revenue_millions)
      FROM companies c
      JOIN company_revenue_annual r ON c.company_id = r.company_id
      GROUP BY c.name
      ORDER BY AVG(r.revenue_millions) DESC
      LIMIT 5;"
```

### Phase 2: LibreChat Integration

**Prerequisites**:
- Python sidecar running at http://localhost:8001
- MCPtest database accessible at 172.28.91.130:5432
- LibreChat running with MCP support enabled

**Configuration** (`~/LibreChat-Local/librechat.yaml`):
```yaml
version: 1.2.1
mcpServers:
  nl2sql:
    command: npx
    args:
      - -y
      - "@smithery/cli@latest"
      - run
      - /home/noahc/nl2sql-project/mcp-server-nl2sql/.smithery/index.cjs
      - --config
      - /home/noahc/nl2sql-project/mcp-server-nl2sql/.mcp.json
    serverInstructions: |
      This MCP server provides natural language to SQL conversion for the MCPtest database.

      Use the `nl_query` tool to ask questions about companies and revenue data.
      The tool automatically converts natural language to SQL, validates it, and executes against PostgreSQL.

      Example questions:
      - "How many companies are in the database?"
      - "What company had the highest revenue in 2020?"
      - "Show me the top 5 companies by average revenue"
```

**Testing Checklist**:
- [ ] MCP server appears in LibreChat MCP tools list
- [ ] `nl_query` tool is callable from chat interface
- [ ] Simple queries execute successfully (Q1: "How many companies?")
- [ ] JOIN queries work (Q6: "What company had highest revenue in 2020?")
- [ ] Aggregation queries work (Q10: "Top 5 companies by average revenue")
- [ ] Error handling works (Q19: "Show me all employees")
- [ ] Validator catches dangerous keywords (try: "DROP TABLE companies")
- [ ] LIMIT is auto-added to queries without it
- [ ] Trace information is logged for debugging

### Phase 3: End-to-End Validation

**Full Flow Test**:
```
User Question (LibreChat UI)
    ↓
TypeScript MCP Server (nl_query tool)
    ↓
Python Sidecar HTTP Request (POST /generate_sql)
    ↓
Ollama/Hrida SQL Generation (temperature=0.0)
    ↓
Python Response (SQL + confidence)
    ↓
TypeScript Validator (state machine tokenizer)
    ↓
PostgreSQL EXPLAIN (safety check)
    ↓
PostgreSQL EXECUTE (if EXPLAIN passes)
    ↓
Results to User (formatted table)
```

**Monitoring Points**:
1. **Python sidecar logs**: Check for SQL generation, confidence scores
2. **TypeScript logs**: Check for validation issues, auto-fixes
3. **Database logs**: Check for EXPLAIN/EXECUTE queries
4. **LibreChat UI**: Verify results display correctly

### Phase 4: Repair Loop Testing

**Scenarios to Test**:

**Scenario 1: Unknown Table (Repairable)**
```
Q: "How many customers are there?"
Expected Flow:
- Attempt 1: HridaAI generates "SELECT COUNT(*) FROM customers;"
- Validator detects UNKNOWN_TABLE
- Repair attempt: Python gets validator_issues, tries "SELECT COUNT(*) FROM companies;"
- Success on attempt 2
```

**Scenario 2: Dangerous Keyword (Fail-Fast)**
```
Q: "DROP TABLE companies"
Expected Flow:
- Attempt 1: HridaAI generates "DROP TABLE companies;"
- Validator detects DANGEROUS_KEYWORD
- Fail immediately (action: fail_fast), no repair attempt
- Return error to user
```

**Scenario 3: PostgreSQL Syntax Error (Repairable)**
```
Q: "How many companies founded in each decade?"
Expected Flow:
- Attempt 1: "SELECT EXTRACT(DECADE FROM year)..." (invalid)
- EXPLAIN fails with SQLSTATE 42883 (undefined function)
- Repair attempt: Python gets postgres_error, tries "(year / 10) * 10"
- Success on attempt 2
```

**Scenario 4: Max Attempts Exceeded**
```
Q: Deliberately complex/ambiguous question
Expected Flow:
- Attempt 1: Invalid SQL
- Repair attempt 2: Still invalid
- Repair attempt 3: Still invalid
- Max attempts (3) reached
- Return safe failure message to user
```

### Phase 5: Performance Testing

**Metrics to Track**:
- **Latency**:
  - Python SQL generation: Target <5s (includes Ollama call)
  - TypeScript validation: Target <50ms
  - PostgreSQL EXPLAIN: Target <100ms
  - Total query time: Target <6s
- **Success Rate**:
  - Simple queries (Level 1-2): Target >95%
  - Complex queries (Level 3-4): Target >85%
  - Overall: Target >90%
- **Repair Rate**:
  - Questions requiring 1 repair: Expect ~10-15%
  - Questions requiring 2+ repairs: Expect <5%
  - Max attempts exceeded: Expect <3%

---

## Semantic Validation Layer (v1.3.0)

### Problem: Model Fixation on Prompt Examples

**Discovered in Test 4**: HridaAI sometimes generates SQL that uses hardcoded values from the prompt examples instead of entities from the actual question.

**Example**:
```
Question: "Which state is Titan Financial Services in?"
Expected: SELECT state FROM companies WHERE name = 'Titan Financial Services';
Actual:   SELECT c.name FROM companies c WHERE c.state = 'CA';  ← WRONG!
```

The model saw `'CA'` in a prompt example and used it instead of parsing the question.

### Solution: Semantic Validation + Auto-Repair

**Architecture**:
```
┌─────────────────────┐
│ 1. Generate SQL     │
│    (Hrida/Ollama)   │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ 2. Semantic Check   │  ← NEW LAYER
│    (Python)         │
└──────────┬──────────┘
           │
      ┌────┴────┐
      │ Valid?  │
      └────┬────┘
     No    │    Yes
      ┌────┴────┐
      │         │
      ▼         ▼
┌──────────┐  ┌────────────────┐
│Auto-Repair│  │Structural Valid│
│(1 attempt)│  │   & Execute    │
└──────────┘  └────────────────┘
```

### Implementation (Python Sidecar)

**semantic_validator.py** checks:

1. **Entity Extraction**: Company names mentioned in question appear in SQL
2. **Intent Alignment**: "which state" → SQL must SELECT state column
3. **Hallucination Detection**: Values in SQL (states, years) match question
4. **Column Validation**: Selected columns match question semantics

```python
def validate_semantic_match(question: str, sql: str, schema: dict) -> Tuple[bool, List[Dict]]:
    """
    Validate SQL semantically matches the question.

    Returns (is_valid, issues) where:
    - is_valid: True if no 'error' severity issues
    - issues: List of {code, severity, message, suggestion, ...}
    """
    issues = []

    # 1. Check company names
    companies = extract_company_names(question)
    for company in companies:
        if company not in sql:
            issues.append({
                'code': 'MISSING_ENTITY',
                'severity': 'error',
                'message': f"Question mentions '{company}' but SQL doesn't reference it",
                'suggestion': f"Add WHERE name = '{company}'"
            })

    # 2. Check query intent
    intent = classify_query_intent(question)
    if intent == 'lookup_state' and 'state' not in sql.lower():
        issues.append({
            'code': 'WRONG_SELECT',
            'severity': 'warning',
            'message': "Question asks 'which state' but SQL doesn't SELECT state"
        })

    # 3. Check for hallucinated values
    sql_states = extract_state_codes(sql)
    question_states = extract_state_codes(question)
    for state in sql_states:
        if state not in question_states:
            issues.append({
                'code': 'HALLUCINATED_VALUE',
                'severity': 'error',
                'message': f"SQL filters by state '{state}' but question doesn't mention it"
            })

    return (not any(i['severity'] == 'error' for i in issues), issues)
```

### Auto-Repair Integration

**app.py** automatically repairs semantic issues:

```python
# After SQL generation
sql, confidence = hrida_client.generate_sql(prompt)

# Semantic validation
semantic_valid, semantic_issues = validate_semantic_match(
    question=request.question,
    sql=sql,
    schema=filtered_schema
)

# Auto-repair if errors found
if not semantic_valid:
    error_issues = [i for i in semantic_issues if i['severity'] == 'error']
    logger.warning(f"Semantic validation failed with {len(error_issues)} errors")

    # Build repair prompt with semantic delta
    repair_prompt = build_repair_prompt(
        question=request.question,
        previous_sql=sql,
        schema=filtered_schema,
        semantic_issues=semantic_issues
    )

    # Attempt repair (single attempt)
    repaired_sql, repaired_confidence = hrida_client.generate_sql(repair_prompt)

    # Re-validate
    repair_valid, repair_issues = validate_semantic_match(...)
    if repair_valid:
        sql = repaired_sql
        confidence = max(0.6, repaired_confidence - 0.1)
        notes = f"Auto-repaired: {', '.join([i['code'] for i in error_issues])}"
```

### Repair Delta Template

```python
REPAIR_DELTA_SEMANTIC = """
## Semantic Mismatch Detected

Your SQL does not correctly reference entities mentioned in the question.

{semantic_issues_formatted}

**Critical:** If the question asks about a specific company (e.g., "Titan Financial Services"),
your SQL MUST include `WHERE name = 'Titan Financial Services'` (or similar).

**Previous SQL That Missed Entities:**
```sql
{previous_sql}
```

Generate corrected SQL that properly references ALL entities from the question.
"""
```

### Prompt Improvements

**Removed problematic example**:
```python
# Before (caused model to fixate on 'CA')
3. **String Literals:** Always use single quotes for strings
   - RIGHT: `WHERE state = 'CA'`

# After
3. **String Literals:** Always use single quotes for strings
   - RIGHT: `WHERE column = 'value'`
```

**Added few-shot patterns**:
```python
## Example Queries (patterns only - use actual values from the question)

- "Which state is [Company] in?" → `SELECT state FROM companies WHERE name = '[Company]'`
- "How many companies in [State]?" → `SELECT COUNT(*) FROM companies WHERE state = '[STATE_CODE]'`
- "Show revenue for [Company]" → `SELECT r.* FROM ... WHERE c.name = '[Company]'`

**IMPORTANT:** Extract actual entity names from the question. If the question mentions
a specific company name, your SQL MUST include that exact name in a WHERE clause.
```

### Validation Rule Reference

| Code | Severity | Description | Auto-Repair |
|------|----------|-------------|-------------|
| `MISSING_ENTITY` | error | Question mentions entity not in SQL | ✅ |
| `WRONG_SELECT` | warning | Query intent doesn't match SELECT | ✅ |
| `HALLUCINATED_VALUE` | error | SQL has values not in question | ✅ |
| `WRONG_YEAR` | warning | SQL uses different year than question | ✅ |

### Testing

Verify semantic validation catches Q3-type errors:
```bash
curl -X POST http://localhost:8001/generate_sql \
  -H "Content-Type: application/json" \
  -d '{"question": "Which state is Titan Financial Services in?", "database_id": "mcptest"}'

# Expected: SQL should contain "Titan Financial Services" and SELECT state
# If semantic repair triggered, notes field will show what was fixed
```

---

### Known Integration Issues

**Issue 1: MCP Server Won't Start**
- **Symptom**: LibreChat shows "MCP server failed to initialize"
- **Fix**: Check `.mcp.json` database connection string is correct
- **Fix**: Ensure Python sidecar is running at http://localhost:8001

**Issue 2: Timeout on Complex Queries**
- **Symptom**: Ollama times out after 30s
- **Fix**: Increase `OLLAMA_TIMEOUT` env var in Python sidecar
- **Fix**: Use smaller/faster model for dev testing

**Issue 3: Quote Escaping in Results**
- **Symptom**: Company names with quotes display incorrectly
- **Fix**: Ensure JSON serialization preserves quotes
- **Fix**: Check LibreChat's MCP response handling

**Issue 4: EXPLAIN Fails on Valid SQL**
- **Symptom**: Valid SQL rejected by EXPLAIN
- **Fix**: Check PostgreSQL permissions allow EXPLAIN
- **Fix**: Verify read-only role is configured correctly

---

## Change Log

**v1.3.0** (2026-01-14)
- Added semantic validation layer (catches entity mismatches)
- Auto-repair for semantic issues (MISSING_ENTITY, HALLUCINATED_VALUE)
- Removed problematic 'CA' example from prompt (caused model fixation)
- Added few-shot query patterns to guide entity extraction
- New semantic_validator.py module in Python sidecar
- Test 4 baseline: 63% success rate (target improvement with semantic repair)

**v1.2.0** (2026-01-14)
- Implemented state machine tokenizer
- Fixed semicolon handling (optional, not required)
- Fixed keyword checks (ignore strings/comments)
- Added dangerous function blocking
- Added issue compression for repair
- Documented all design decisions and gotchas
- Added comprehensive integration testing guide

**v1.0.0** (2026-01-13)
- Initial MVP validator with 5 basic rules
- Naive split(';') for multiple statements (fixed in v1.2.0)
- Basic keyword blocking (improved in v1.2.0)
